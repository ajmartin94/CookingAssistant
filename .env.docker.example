# Docker Environment Variables
# Copy this file to .env.docker and customize as needed
# Usage: docker compose --env-file .env.docker up -d

# =============================================================================
# SECURITY (REQUIRED FOR PRODUCTION)
# =============================================================================

# JWT secret key - MUST be changed in production!
# Generate with: openssl rand -hex 32
SECRET_KEY=change-me-in-production-make-it-long-and-random

# =============================================================================
# AI CONFIGURATION
# =============================================================================

# LLM model to use (format: provider/model)
# Examples:
#   ollama/llama3.1:8b        - Local Ollama (default, free)
#   ollama/mistral:7b         - Alternative local model
#   anthropic/claude-3-haiku  - Anthropic API (requires key)
#   openai/gpt-4o-mini        - OpenAI API (requires key)
LLM_MODEL=ollama/llama3.1:8b

# API keys for cloud providers (optional, only if using cloud models)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# =============================================================================
# FRONTEND BUILD ARGS
# =============================================================================

# Backend API URL (as seen from browser)
VITE_API_URL=http://localhost:8000

# Enable AI chat features
VITE_ENABLE_AI_FEATURES=true

# =============================================================================
# HARDWARE CONFIGURATION
# =============================================================================

# Uncomment to enable GPU support for Ollama (requires NVIDIA GPU + drivers)
# COMPOSE_PROFILES=gpu
